{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2627dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b3a61e",
   "metadata": {},
   "source": [
    "# Dictionary parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a961bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_path = r'stuff/dict.opcorpora.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912fd94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dict(xml_file_path):\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0469ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_root = parse_dict(dict_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31597af0",
   "metadata": {},
   "source": [
    "# Parsing lemmata from dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c87426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f04bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lemmata(root):\n",
    "    lemmata_dict = defaultdict(list)\n",
    "    lemmata_section = root.find('lemmata')\n",
    "\n",
    "    for lemma_elem in lemmata_section.findall('lemma'):\n",
    "        l_elem = lemma_elem.find('l')\n",
    "        lemma_text = l_elem.get('t', '')\n",
    "        \n",
    "        first_g_elem = l_elem.find('g')\n",
    "        main_grammem = first_g_elem.get('v', '') if first_g_elem is not None else ''\n",
    "                    \n",
    "        for f_elem in lemma_elem.findall('f'):\n",
    "            form_text = f_elem.get('t', '')\n",
    "            if form_text: \n",
    "                new_entry = (lemma_text, main_grammem)\n",
    "                \n",
    "                if new_entry not in lemmata_dict[form_text]:\n",
    "                    lemmata_dict[form_text].append(new_entry)\n",
    "            \n",
    "    return dict(lemmata_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a46115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmata_dict = parse_lemmata(dict_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3960a5",
   "metadata": {},
   "source": [
    "# Tokenize and lemmatize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75dc6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):  \n",
    "    tokens = re.findall(r'\\w+', text)\n",
    "    return [token for token in tokens if token]\n",
    "\n",
    "def normalize(word):\n",
    "    return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8238722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(input_text, lemmata_dict, llm):\n",
    "    lines = input_text.strip().split('\\n')\n",
    "    results = []\n",
    "    \n",
    "    for line in lines:\n",
    "        tokens = tokenize(line)\n",
    "        processed_tokens = []\n",
    "        \n",
    "        for token in tokens:\n",
    "            normalized = normalize(token)\n",
    "            \n",
    "            if normalized in lemmata_dict:\n",
    "                possible_lemmas = lemmata_dict[normalized]\n",
    "                \n",
    "                if len(possible_lemmas) == 1:\n",
    "                    lemma, grammem = possible_lemmas[0]\n",
    "                else:\n",
    "                    print(f\"Омонимия: {token} -> {possible_lemmas}\")\n",
    "                    lemma, grammem = llm.disambiguate(token, possible_lemmas, line)\n",
    "                    \n",
    "                processed_tokens.append(f\"{token}{{{lemma}={grammem}}}\")\n",
    "            else:\n",
    "                # Неизвестное слово\n",
    "                print(f\"Неизвестное слово: {token}\")\n",
    "                lemma, grammem = llm.guess_unknown_word(token, line)\n",
    "                processed_tokens.append(f\"{token}{{{lemma}={grammem}}}\")\n",
    "        \n",
    "        results.append(' '.join(processed_tokens))\n",
    "    \n",
    "    return '\\n'.join(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02570c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(input_text, lemmata_dict, llm):\n",
    "    lines = input_text.strip().split('\\n')\n",
    "    results = []\n",
    "    \n",
    "    for line in lines:\n",
    "        tokens = tokenize(line)\n",
    "        processed_tokens = []\n",
    "        \n",
    "        for token in tokens:\n",
    "            normalized = normalize(token)\n",
    "            \n",
    "            if normalized in lemmata_dict:\n",
    "                possible_lemmas = lemmata_dict[normalized]\n",
    "                \n",
    "                if len(possible_lemmas) == 1:\n",
    "                    lemma, grammem = possible_lemmas[0]\n",
    "            else:\n",
    "                print(f\"Омонимия: {token} -> {possible_lemmas}\")\n",
    "                lemma, grammem = disambiguate(llm, token, possible_lemmas, line)\n",
    "\n",
    "            processed_tokens.append(f\"{token}{{{lemma}={grammem}}}\")\n",
    "        \n",
    "        else:\n",
    "\n",
    "            lemma, grammem = guess_unknown_word(token)\n",
    "            processed_tokens.append(f\"{token}{{{lemma}={grammem}}}\")\n",
    "        results.append(' '.join(processed_tokens))\n",
    "    \n",
    "    return '\\n'.join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c89955b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''люблю русскую печь и печь пироги'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cf985bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lemmata_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m process_text(text, \u001b[43mlemmata_dict\u001b[49m, llm)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lemmata_dict' is not defined"
     ]
    }
   ],
   "source": [
    "process_text(text, lemmata_dict, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a274b9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
