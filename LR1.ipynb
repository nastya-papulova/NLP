{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2627dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b3a61e",
   "metadata": {},
   "source": [
    "# Dictionary parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a961bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_path = r'stuff/dict.opcorpora.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912fd94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dict(xml_file_path):\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0469ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_root = parse_dict(dict_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31597af0",
   "metadata": {},
   "source": [
    "# Parsing lemmata from dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c87426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f04bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_lemmata(root):\n",
    "    lemmata_dict = defaultdict(list)\n",
    "    lemmata_section = root.find('lemmata')\n",
    "\n",
    "    for lemma_elem in lemmata_section.findall('lemma'):\n",
    "        l_elem = lemma_elem.find('l')\n",
    "        lemma_text = l_elem.get('t', '')\n",
    "        \n",
    "        first_g_elem = l_elem.find('g')\n",
    "        main_grammem = first_g_elem.get('v', '') if first_g_elem is not None else ''\n",
    "                    \n",
    "        for f_elem in lemma_elem.findall('f'):\n",
    "            form_text = f_elem.get('t', '')\n",
    "            if form_text: \n",
    "                new_entry = (lemma_text, main_grammem)\n",
    "                \n",
    "                if new_entry not in lemmata_dict[form_text]:\n",
    "                    lemmata_dict[form_text].append(new_entry)\n",
    "            \n",
    "    return dict(lemmata_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a46115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmata_dict = parse_lemmata(dict_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb4684d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('абдужалия', 'NOUN')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmata_dict['абдужалия']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3960a5",
   "metadata": {},
   "source": [
    "# Tokenize and lemmatize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75dc6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):  \n",
    "    tokens = re.findall(r'\\w+', text)\n",
    "    return [token for token in tokens if token]\n",
    "\n",
    "def normalize(word):\n",
    "    return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f34b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02570c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(input_text, lemmata_dict):\n",
    "    lines = input_text.strip().split('\\n')\n",
    "    results = []\n",
    "    \n",
    "    for line in lines:\n",
    "        tokens = tokenize(line)\n",
    "        processed_tokens = []\n",
    "        \n",
    "        for token in tokens:\n",
    "            normalized = normalize(token)\n",
    "            \n",
    "            if normalized in lemmata_dict:\n",
    "                lemma, grammem = lemmata_dict[normalized]\n",
    "                processed_tokens.append(f\"{token}{{{lemma}={grammem}}}\")\n",
    "            else:\n",
    "                processed_tokens.append(f\"{token}{{{normalized}=UNKN}}\")\n",
    "        \n",
    "        results.append(' '.join(processed_tokens))\n",
    "    \n",
    "    return '\\n'.join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c89955b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Стала стабильнее экономическая и политическая обстановка, предприятия вывели из тени зарплаты сотрудников.\n",
    "Все Гришины одноклассники уже побывали за границей, он был чуть ли не единственным, кого не вывозили никуда дальше Красной Пахры.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0cf985bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Стала{стал=VERB} стабильнее{стабильнее=COMP} экономическая{экономический=ADJF} и{и=CONJ} политическая{политический=ADJF} обстановка{обстановка=NOUN} предприятия{предприятие=NOUN} вывели{вывел=VERB} из{из=PREP} тени{теню=VERB} зарплаты{зарплата=NOUN} сотрудников{сотрудник=NOUN}\\nВсе{весь=ADJF} Гришины{гришины=NOUN} одноклассники{одноклассник=NOUN} уже{уж=NOUN} побывали{побывал=VERB} за{за=PREP} границей{граница=NOUN} он{он=NPRO} был{есть=VERB} чуть{чуть=ADVB} ли{ли=CONJ} не{не=PRCL} единственным{единственный=ADJF} кого{кто=NPRO} не{не=PRCL} вывозили{вывожу=VERB} никуда{никуда=ADVB} дальше{дальше=COMP} Красной{красная=NOUN} Пахры{пахра=NOUN}'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_text(text, lemmata_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
